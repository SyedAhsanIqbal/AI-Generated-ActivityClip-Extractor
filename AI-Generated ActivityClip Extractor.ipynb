{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb435416",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input, decode_predictions\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "# Initialize MobileNetV2 and BERT\n",
    "model_mobilenet = MobileNetV2(weights='imagenet', include_top=True)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model_bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def generate_captions(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    captions = []\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        # Preprocess the frame for MobileNetV2\n",
    "        frame = cv2.resize(frame, (224, 224))\n",
    "        frame_array = preprocess_input(frame)\n",
    "        frame_array = np.expand_dims(frame_array, axis=0)\n",
    "\n",
    "        # Predict and decode predictions\n",
    "        preds = model_mobilenet.predict(frame_array)\n",
    "        decoded = decode_predictions(preds, top=1)[0][0][1]\n",
    "        captions.append(decoded)\n",
    "    cap.release()\n",
    "    return captions\n",
    "\n",
    "def calculate_similarity(captions, description):\n",
    "    description_encoded = tokenizer(description, return_tensors='pt')\n",
    "    description_output = model_bert(**description_encoded)\n",
    "    description_embedding = description_output.last_hidden_state[:, 0, :]\n",
    "\n",
    "    matching_indices = []\n",
    "    for i, caption in enumerate(captions):\n",
    "        caption_encoded = tokenizer(caption, return_tensors='pt')\n",
    "        caption_output = model_bert(**caption_encoded)\n",
    "        caption_embedding = caption_output.last_hidden_state[:, 0, :]\n",
    "\n",
    "        # Cosine similarity\n",
    "        cos_sim = torch.nn.functional.cosine_similarity(description_embedding, caption_embedding)\n",
    "        if cos_sim.item() > 0.8:  # Threshold for similarity\n",
    "            matching_indices.append(i)\n",
    "\n",
    "    return matching_indices\n",
    "\n",
    "def clip_video(video_path, output_path, frame_indices, fps=30):\n",
    "    start_time = frame_indices[0] / fps\n",
    "    end_time = (frame_indices[-1] + 1) / fps\n",
    "    video = VideoFileClip(video_path).subclip(start_time, end_time)\n",
    "    video.write_videofile(output_path, codec='libx264')\n",
    "\n",
    "def process_video(video_path, description, output_path):\n",
    "    print(\"Generating captions...\")\n",
    "    captions = generate_captions(video_path)\n",
    "    print(\"Calculating similarities...\")\n",
    "    matching_indices = calculate_similarity(captions, description)\n",
    "    if matching_indices:\n",
    "        print(\"Clipping video...\")\n",
    "        clip_video(video_path, output_path, matching_indices)\n",
    "        print(f\"Video successfully saved to {output_path}\")\n",
    "    else:\n",
    "        print(\"No matching activities found.\")\n",
    "\n",
    "# Example usage\n",
    "video_path = 'input_video.mp4'\n",
    "activity_description = 'dog playing'\n",
    "output_video_path = 'output_video.mp4'\n",
    "process_video(video_path, activity_description, output_video_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01498718",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
